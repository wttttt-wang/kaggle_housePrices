{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART ONE: Data Reading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def read_data():\n",
    "    #step1:reading csv data\n",
    "    train = pd.read_csv('../input/train.csv')\n",
    "    test = pd.read_csv('../input/test.csv')\n",
    "    #train.head()   # take a brief look at training data\n",
    "    all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition'])) # concat training&test data\n",
    "    return train,test,all_data\n",
    "#train,test,all_data = read_data()\n",
    "def model_input():\n",
    "    alldata_after_filling_missing_skew = pd.read_csv('../input/alldata_after_filling_missing_skew.csv')\n",
    "    y = pd.read_csv('../input/train_label_skew',header=None)\n",
    "    test_label = pd.read_csv('../input/test_id',header=None)\n",
    "    return alldata_after_filling_missing_skew,y,test_label\n",
    "#alldata_after_filling_missing_skew,y,test_label = model_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe preprocessing apart from dimensional reduction is :\\n@ missing data filling: \\n    RandomForest filling for important features(highly relevant to SalePrice);\\n    another value filling for features having many missing value, or its missing value has some meaning.\\n    mean()/mode() filling for other features\\n@ data transform: get_dummies for categorical features\\n@ log transform for SalePrice and some skewed features\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "the preprocessing apart from dimensional reduction is :\n",
    "@ missing data filling: \n",
    "    RandomForest filling for important features(highly relevant to SalePrice);\n",
    "    another value filling for features having many missing value, or its missing value has some meaning.\n",
    "    mean()/mode() filling for other features\n",
    "@ data transform: get_dummies for categorical features\n",
    "@ log transform for SalePrice and some skewed features\n",
    "''' \n",
    "#alldata_after_filling_missing_skew = pd.read_csv('../input/alldata_after_filling_missing_skew.csv')\n",
    "#y = pd.read_csv('../input/train_label_skew',header=None)\n",
    "#import xgboost as xgb\n",
    "#model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\n",
    "#model_xgb.fit(alldata_after_filling_missing_skew.iloc[:1460],y)\n",
    "#pre_val = np.expm1(pd.DataFrame(model_xgb.predict(alldata_after_filling_missing_skew.iloc[1460:])))\n",
    "#test_label = pd.read_csv('../input/test_id',header=None)\n",
    "#result = pd.DataFrame()\n",
    "#result['Id'] = test_label[0]\n",
    "#result['SalePrice'] = pre_val[0]\n",
    "#result.to_csv('../input/result_xgb_1123_nofeaselec_skew.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PART FOUR: Feature Decomposition\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Note that the input df must not have categorial features or missing value,\n",
    "# do this after preprocessing fo filling missing value and feature transformation\n",
    "def pca_reduc(df, num_fea_toleave='mle'):\n",
    "    # @return type: pd.DataFrame\n",
    "    pca = PCA(n_components=num_fea_toleave)\n",
    "    after_pca = pca.fit_transform(df)\n",
    "    print 'Percentage of variance explained by each of the selected components:'\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    #print pd.DataFrame(new).info()\n",
    "    return pd.DataFrame(after_pca)\n",
    "#all_data = dummy_all(all_data)\n",
    "#all_data.fillna(all_data.mean(),inplace=True)\n",
    "#all_data = pca_reduc(all_data,30)\n",
    "#all_data.info(verbose=True, max_cols=1000)\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "# Kernel PCA ==> non-linear dimensionality reduction through the use of kernels\n",
    "# Somewhat like kernel in SVM\n",
    "# kernel = “linear” | “poly” | “rbf” | “sigmoid” | “cosine” | “precomputed”\n",
    "def kernelpca_reduc(df, kernel='linear',num_fea_toleave=50):\n",
    "    kpca = KernelPCA(n_components=num_fea_toleave,kernel = kernel,n_jobs=-1)\n",
    "    after_kpca = kpca.fit_transform(df)\n",
    "    print 'the selected features Eigenvalues in decreasing order:'\n",
    "    print (kpca.lambdas_)\n",
    "    return pd.DataFrame(after_kpca)\n",
    "#all_data = dummy_all(all_data)\n",
    "#all_data.fillna(all_data.mean(),inplace=True)\n",
    "#all_data = kernelpca_reduc(all_data,kernel='rbf',num_fea_toleave=50)\n",
    "#print all_data.shape\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Dimensionality reduction using truncated SVD\n",
    "def truncatedSVD_reduc(df,num_fea_toleave=50):\n",
    "    # provide a random_state to get stable output\n",
    "    svd = TruncatedSVD(n_components=num_fea_toleave, n_iter=7, random_state=42)\n",
    "    after_trans = svd.fit_transform(df)\n",
    "    print 'Percentage of variance explained by each of the selected components:'\n",
    "    print(svd.explained_variance_ratio_) \n",
    "    return pd.DataFrame(after_trans)\n",
    "#all_data = dummy_all(all_data)\n",
    "#all_data.fillna(all_data.mean(),inplace=True)\n",
    "#all_data = truncatedSVD_reduc(all_data,num_fea_toleave=50)\n",
    "#print all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART FIVE: Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "# RFECV: Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.\n",
    "def fea_sel_rfecv(train_x,train_y,test_x,estimator):\n",
    "    rfecv = RFECV(estimator=estimator,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    after_d = rfecv.fit_transform(train_x,train_y)\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score(neg_mean_squared_error)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    return pd.DataFrame(after_d),pd.DataFrame(rfecv.transform(test_x))\n",
    "#alldata_nomissing = pd.read_csv('../input/alldata_after_filling_missing.csv')\n",
    "#from sklearn import svm\n",
    "#clf = svm.LinearSVR()\n",
    "#after_d,after_d_test = (fea_sel_rfecv(alldata_nomissing.iloc[:1460],train['SalePrice'],alldata_nomissing.iloc[1460:],clf))\n",
    "#print after_d.shape\n",
    "#print after_d_test.shape\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# u can see from 'SelectFromModel' that this method use model result to select features, 'Wrapper'\n",
    "# estimator: a supervised model with fit() method\n",
    "def fea_sel_tree(train_x,train_y,estimator):\n",
    "    estimator = estimator.fit(train_x,train_x)\n",
    "    print 'feature importances in this model',\n",
    "    print sorted(estimator.feature_importances_,reverse=True)\n",
    "    model = SelectFromModel(estimator,prefit = True)\n",
    "    after_sel = model.transform(train_x)\n",
    "    return pd.DataFrame(after_sel)\n",
    "#train = dummy_all(train)\n",
    "#train.fillna(train.mean(),inplace=True)\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#clf = RandomForestRegressor(random_state=0,n_estimators=50)\n",
    "#print fea_sel_tree(train.iloc[:,1:-1],train['SalePrice'],clf).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "alldata_after_filling_missing_skew,y,test_label = model_input()\n",
    "def rmse_cv(model, data_x, data_y):\n",
    "    rmse= np.sqrt(-cross_val_score(model, data_x, data_y, scoring=\"mean_squared_error\", cv = 3))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of variance explained by each of the selected components:\n",
      "[  9.66823521e-01   2.47076500e-02   4.61466268e-03   2.38038610e-03\n",
      "   2.57704922e-04   1.78065391e-04   1.53568252e-04   1.21621284e-04\n",
      "   1.17793406e-04   8.43552745e-05   7.28115983e-05   5.96685672e-05\n",
      "   5.26004969e-05   4.11435019e-05   3.52181392e-05   3.19541174e-05\n",
      "   1.99598446e-05   1.88707986e-05   1.74078551e-05   1.17572974e-05\n",
      "   1.06521573e-05   1.03831585e-05   8.72509347e-06   8.38515095e-06\n",
      "   7.99378491e-06   7.08155812e-06   6.23161041e-06   5.65530391e-06\n",
      "   5.29206753e-06   4.95437884e-06   4.75773594e-06   4.54058438e-06\n",
      "   4.34970503e-06   3.78027993e-06   3.68309566e-06   3.56545801e-06\n",
      "   3.42067221e-06   3.29100327e-06   3.13612475e-06   3.05174734e-06\n",
      "   2.84474246e-06   2.74807881e-06   2.65150242e-06   2.59402129e-06\n",
      "   2.51982854e-06   2.45756827e-06   2.39573910e-06   2.29183833e-06\n",
      "   2.15166315e-06   2.12193072e-06   2.05204519e-06   1.96357995e-06\n",
      "   1.83561234e-06   1.76543061e-06   1.67923616e-06   1.59397972e-06\n",
      "   1.55257360e-06   1.47732127e-06   1.42498805e-06   1.34321195e-06\n",
      "   1.33018898e-06   1.27766263e-06   1.23968917e-06   1.23265139e-06\n",
      "   1.18760922e-06   1.15335674e-06   1.14764641e-06   1.08021044e-06\n",
      "   1.00746991e-06   9.66581195e-07   9.59447557e-07   9.33238004e-07\n",
      "   8.93899844e-07   8.34997373e-07   8.25536610e-07   7.99593708e-07\n",
      "   7.76347858e-07   7.16815740e-07   6.97903132e-07   6.82818087e-07\n",
      "   6.51795887e-07   6.33109138e-07   6.10471633e-07   5.90413888e-07\n",
      "   5.73374714e-07   5.65486580e-07   5.32559225e-07   5.15074066e-07\n",
      "   5.01982534e-07   4.84929471e-07   4.67111215e-07   4.62565052e-07\n",
      "   4.48414258e-07   4.36466412e-07   4.30567072e-07   4.14217652e-07\n",
      "   4.09764253e-07   4.02080328e-07   3.92976308e-07   3.82740231e-07\n",
      "   3.79486035e-07   3.68882047e-07   3.65868288e-07   3.53387503e-07\n",
      "   3.51762581e-07   3.42955527e-07   3.32222667e-07   3.24164700e-07\n",
      "   3.19026553e-07   3.09981865e-07   3.05275550e-07   2.99328091e-07\n",
      "   2.94380204e-07   2.84763942e-07   2.79411087e-07   2.61906340e-07\n",
      "   2.56839157e-07   2.52637585e-07   2.44545365e-07   2.42709199e-07\n",
      "   2.38530477e-07   2.34684715e-07   2.33350962e-07   2.24371394e-07\n",
      "   2.23607428e-07   2.18877485e-07   2.12962353e-07   2.11010942e-07\n",
      "   2.08461661e-07   1.97582584e-07   1.87547363e-07   1.84595441e-07\n",
      "   1.81668184e-07   1.75165825e-07   1.73346797e-07   1.66638848e-07\n",
      "   1.64470155e-07   1.58833826e-07   1.57898401e-07   1.53229786e-07\n",
      "   1.46355230e-07   1.45691720e-07   1.40037369e-07   1.35401809e-07\n",
      "   1.34543150e-07   1.29956473e-07   1.28780712e-07   1.26780005e-07\n",
      "   1.24390304e-07   1.21927230e-07   1.17455826e-07   1.15654249e-07\n",
      "   1.07234403e-07   1.06729685e-07   1.03375656e-07   1.01908469e-07\n",
      "   1.00766853e-07   9.55128175e-08   9.30965214e-08   9.19141500e-08\n",
      "   8.63313526e-08   8.37190705e-08   8.30659478e-08   8.02738877e-08\n",
      "   7.71834312e-08   7.61651936e-08   7.54604861e-08   7.11461247e-08\n",
      "   7.00890699e-08   6.71934837e-08   6.62382668e-08   6.47855407e-08\n",
      "   6.43108866e-08   6.10820191e-08   6.04706848e-08   5.92864726e-08\n",
      "   5.77400717e-08   5.64909435e-08   5.46860118e-08   5.29111710e-08\n",
      "   5.26011598e-08   5.09444618e-08   4.99165746e-08   4.88420926e-08\n",
      "   4.74935680e-08   4.67538969e-08   4.42763962e-08   4.28490287e-08\n",
      "   4.27883545e-08   4.05106158e-08   3.79419079e-08   3.68711764e-08\n",
      "   3.60270099e-08   3.53053494e-08   3.37635081e-08   3.22752426e-08\n",
      "   3.02624469e-08   2.90947895e-08   2.83969907e-08   2.80786816e-08]\n",
      "[ 0.16004103  0.18244433  0.15433193]\n"
     ]
    }
   ],
   "source": [
    "alldata_after_filling_missing_skew,y,test_label = model_input()\n",
    "num_fea_toleave = 200  # need \n",
    "alldata_rec = pca_reduc(alldata_after_filling_missing_skew,num_fea_toleave)\n",
    "import xgboost as xgb\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\n",
    "print rmse_cv(model_xgb,alldata_rec.iloc[:1460],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of variance explained by each of the selected components:\n",
      "[  9.66823521e-01   2.47076500e-02   4.61466268e-03   2.38038610e-03\n",
      "   2.57704922e-04   1.78065391e-04   1.53568252e-04   1.21621284e-04\n",
      "   1.17793406e-04   8.43552745e-05]\n",
      "[ 0.11345483  0.1393913   0.12302224]\n"
     ]
    }
   ],
   "source": [
    "alldata_after_filling_missing_skew,y,test_label = model_input()\n",
    "num_fea_toleave = 10  # need \n",
    "alldata_rec = kernelpca_reduc(all_data,kernel='rbf',num_fea_toleave=50)\n",
    "import xgboost as xgb\n",
    "model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\n",
    "print rmse_cv(model_xgb,alldata_rec.iloc[:1460],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# actually, we can do some operations on features, and get more features to select.\n",
    "# Its shown that results from features may also work.\n",
    "# for example, alpha = num_buy/num_click do means something in shopping website's analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
