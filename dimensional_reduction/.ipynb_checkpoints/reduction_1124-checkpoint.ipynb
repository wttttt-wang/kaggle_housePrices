{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART ONE: Data Reading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def read_data():\n",
    "    #step1:reading csv data\n",
    "    train = pd.read_csv('../input/train.csv')\n",
    "    test = pd.read_csv('../input/test.csv')\n",
    "    #train.head()   # take a brief look at training data\n",
    "    all_data = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      test.loc[:,'MSSubClass':'SaleCondition'])) # concat training&test data\n",
    "    return train,test,all_data\n",
    "def model_input():\n",
    "    alldata_after_filling_missing_skew = pd.read_csv('../input/alldata_after_filling_missing_skew.csv')\n",
    "    y = pd.read_csv('../input/train_label_skew',header=None)\n",
    "    test_label = pd.read_csv('../input/test_id',header=None)\n",
    "    return alldata_after_filling_missing_skew,y,test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe preprocessing apart from dimensional reduction is :\\n@ missing data filling: \\n    RandomForest filling for important features(highly relevant to SalePrice);\\n    another value filling for features having many missing value, or its missing value has some meaning.\\n    mean()/mode() filling for other features\\n@ data transform: get_dummies for categorical features\\n@ log transform for SalePrice and some skewed features\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "the preprocessing apart from dimensional reduction is :\n",
    "@ missing data filling: \n",
    "    RandomForest filling for important features(highly relevant to SalePrice);\n",
    "    another value filling for features having many missing value, or its missing value has some meaning.\n",
    "    mean()/mode() filling for other features\n",
    "@ data transform: get_dummies for categorical features\n",
    "@ log transform for SalePrice and some skewed features\n",
    "''' \n",
    "#alldata_after_filling_missing_skew = pd.read_csv('../input/alldata_after_filling_missing_skew.csv')\n",
    "#y = pd.read_csv('../input/train_label_skew',header=None)\n",
    "#import xgboost as xgb\n",
    "#model_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)\n",
    "#model_xgb.fit(alldata_after_filling_missing_skew.iloc[:1460],y)\n",
    "#pre_val = np.expm1(pd.DataFrame(model_xgb.predict(alldata_after_filling_missing_skew.iloc[1460:])))\n",
    "#test_label = pd.read_csv('../input/test_id',header=None)\n",
    "#result = pd.DataFrame()\n",
    "#result['Id'] = test_label[0]\n",
    "#result['SalePrice'] = pre_val[0]\n",
    "#result.to_csv('../input/result_xgb_1123_nofeaselec_skew.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART FOUR: Feature Decomposition\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# Note that the input df must not have categorial features or missing value,\n",
    "# do this after preprocessing fo filling missing value and feature transformation\n",
    "def pca_reduc(df, num_fea_toleave='mle'):\n",
    "    # @return type: pd.DataFrame\n",
    "    pca = PCA(n_components=num_fea_toleave)\n",
    "    after_pca = pca.fit_transform(df)\n",
    "    print 'Percentage of variance explained by each of the selected components:'\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    #print pd.DataFrame(new).info()\n",
    "    return pd.DataFrame(after_pca)\n",
    "#all_data = dummy_all(all_data)\n",
    "#all_data.fillna(all_data.mean(),inplace=True)\n",
    "#all_data = pca_reduc(all_data,30)\n",
    "#all_data.info(verbose=True, max_cols=1000)\n",
    "\n",
    "from sklearn.decomposition import KernelPCA\n",
    "# Kernel PCA ==> non-linear dimensionality reduction through the use of kernels\n",
    "# Somewhat like kernel in SVM\n",
    "# kernel = “linear” | “poly” | “rbf” | “sigmoid” | “cosine” | “precomputed”\n",
    "def kernelpca_reduc(df, kernel='linear',num_fea_toleave=50):\n",
    "    kpca = KernelPCA(n_components=num_fea_toleave,kernel = kernel,n_jobs=-1)\n",
    "    after_kpca = kpca.fit_transform(df)\n",
    "    print 'the selected features Eigenvalues in decreasing order:'\n",
    "    print (kpca.lambdas_)\n",
    "    return pd.DataFrame(after_kpca)\n",
    "#all_data = dummy_all(all_data)\n",
    "#all_data.fillna(all_data.mean(),inplace=True)\n",
    "#all_data = kernelpca_reduc(all_data,kernel='rbf',num_fea_toleave=50)\n",
    "#print all_data.shape\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# Dimensionality reduction using truncated SVD\n",
    "def truncatedSVD_reduc(df,num_fea_toleave=50):\n",
    "    # provide a random_state to get stable output\n",
    "    svd = TruncatedSVD(n_components=num_fea_toleave, n_iter=7, random_state=42)\n",
    "    after_trans = svd.fit_transform(df)\n",
    "    print 'Percentage of variance explained by each of the selected components:'\n",
    "    print(svd.explained_variance_ratio_) \n",
    "    return pd.DataFrame(after_trans)\n",
    "#all_data = dummy_all(all_data)\n",
    "#all_data.fillna(all_data.mean(),inplace=True)\n",
    "#all_data = truncatedSVD_reduc(all_data,num_fea_toleave=50)\n",
    "#print all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART FIVE: Feature Selection\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "# RFECV: Feature ranking with recursive feature elimination and cross-validated selection of the best number of features.\n",
    "def fea_sel_rfecv(train_x,train_y,test_x,estimator):\n",
    "    rfecv = RFECV(estimator=estimator,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    after_d = rfecv.fit_transform(train_x,train_y)\n",
    "    print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "    # Plot number of features VS. cross-validation scores\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score(neg_mean_squared_error)\")\n",
    "    plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "    return pd.DataFrame(after_d),pd.DataFrame(rfecv.transform(test_x))\n",
    "#alldata_nomissing = pd.read_csv('../input/alldata_after_filling_missing.csv')\n",
    "#from sklearn import svm\n",
    "#clf = svm.LinearSVR()\n",
    "#after_d,after_d_test = (fea_sel_rfecv(alldata_nomissing.iloc[:1460],train['SalePrice'],alldata_nomissing.iloc[1460:],clf))\n",
    "#print after_d.shape\n",
    "#print after_d_test.shape\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# u can see from 'SelectFromModel' that this method use model result to select features, 'Wrapper'\n",
    "# estimator: a supervised model with fit() method\n",
    "def fea_sel_tree(train_x,train_y,estimator):\n",
    "    estimator = estimator.fit(train_x,train_x)\n",
    "    print 'feature importances in this model',\n",
    "    print sorted(estimator.feature_importances_,reverse=True)\n",
    "    model = SelectFromModel(estimator,prefit = True)\n",
    "    after_sel = model.transform(train_x)\n",
    "    return pd.DataFrame(after_sel)\n",
    "#train = dummy_all(train)\n",
    "#train.fillna(train.mean(),inplace=True)\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#clf = RandomForestRegressor(random_state=0,n_estimators=50)\n",
    "#print fea_sel_tree(train.iloc[:,1:-1],train['SalePrice'],clf).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "alldata_after_filling_missing_skew,y,test_label = model_input()\n",
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, alldata_after_filling_missing_skew.iloc[:1460], y, scoring=\"mean_squared_error\", cv = 10))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldata_after_filling_missing_skew,y,test_label = model_input()\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# the key in the dict of Pipeline is the name u want give to the step\n",
    "pipe = Pipeline([\n",
    "        ('reduce_dim',PCA()),\n",
    "        ('regression',xgb.XGBRegressor())\n",
    "    ])\n",
    "# optional for feature nums\n",
    "N_FEATURES_OPTIONS = [i for i in range(30,250,50)]\n",
    "#N_ESTIMATOR_OPTIONS = [i for i in range(300,500,20)]\n",
    "N_ESTIMATOR_OPTIONS = [i for i in range(300,400,100)]\n",
    "param_grid=[\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regression__n_estimators': N_ESTIMATOR_OPTIONS\n",
    "    }\n",
    "]\n",
    "\n",
    "'''\n",
    "param_grid=[\n",
    "    {\n",
    "        'reduce_dim': [PCA(iterated_power=7), NMF()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'regression__n_estimators': N_ESTIMATOR_OPTIONS\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [SelectKBest(chi2)],\n",
    "        'reduce_dim__k': N_FEATURES_OPTIONS,\n",
    "        'regression_n_estimators': N_ESTIMATOR_OPTIONS\n",
    "    }\n",
    "]\n",
    "'''\n",
    "grid = GridSearchCV(pipe, cv=3, n_jobs=-1, param_grid=param_grid)\n",
    "grid.fit(alldata_after_filling_missing_skew.iloc[:1460],y)\n",
    "mean_scores = np.array(grid.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 80, 130, 180, 230]\n",
      "[ 0.81127826  0.81891798  0.81821421  0.81933439  0.82010839  0.59906961\n",
      "  0.74412923  0.74475715  0.75498163  0.78805261]\n"
     ]
    }
   ],
   "source": [
    "print N_FEATURES_OPTIONS\n",
    "print mean_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# actually, we can do some operations on features, and get more features to select.\n",
    "# Its shown that results from features may also work.\n",
    "# for example, alpha = num_buy/num_click do means something in shopping website's analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
